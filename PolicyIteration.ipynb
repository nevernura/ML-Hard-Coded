{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGactTMFice+z/EnJmT5dT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTuF9X5zrNhl","executionInfo":{"status":"ok","timestamp":1714458281054,"user_tz":-330,"elapsed":5,"user":{"displayName":"LAMMIBERT SUMER","userId":"10522119435643663185"}},"outputId":"3ada7fb3-020a-4846-9735-de6afe7c7ee3"},"outputs":[{"output_type":"stream","name":"stdout","text":["The initial random policy is:\n","\n","| Down  | Down  | Right | +1    |\n","| Right | WALL  | Down  | -1    |\n","| Left  | Left  | Right | Up    |\n","\n","During the policy iteration:\n","\n","| Right | Right | Right | +1    |\n","| Up    | WALL  | Up    | -1    |\n","| Up    | Left  | Left  | Up    |\n","\n","| Right | Right | Right | +1    |\n","| Up    | WALL  | Left  | -1    |\n","| Up    | Left  | Left  | Left  |\n","\n","| Right | Right | Right | +1    |\n","| Up    | WALL  | Left  | -1    |\n","| Up    | Left  | Left  | Down  |\n","\n","The optimal policy is:\n","\n","| Right | Right | Right | +1    |\n","| Up    | WALL  | Left  | -1    |\n","| Up    | Left  | Left  | Down  |\n","\n"]}],"source":["import random\n","\n","# Arguments\n","REWARD = -0.01 # constant reward for non-terminal states\n","DISCOUNT = 0.99\n","MAX_ERROR = 10**(-3)\n","\n","# Set up the initial environment\n","NUM_ACTIONS = 4\n","ACTIONS = [(1, 0), (0, -1), (-1, 0), (0, 1)] # Down, Left, Up, Right\n","NUM_ROW = 3\n","NUM_COL = 4\n","U = [[0, 0, 0, 1], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]]\n","policy = [[random.randint(0, 3) for j in range(NUM_COL)] for i in range(NUM_ROW)] # construct a random policy\n","\n","# Visualization\n","def printEnvironment(arr, policy=False):\n","    res = \"\"\n","    for r in range(NUM_ROW):\n","        res += \"|\"\n","        for c in range(NUM_COL):\n","            if r == c == 1:\n","                val = \"WALL\"\n","            elif r <= 1 and c == 3:\n","                val = \"+1\" if r == 0 else \"-1\"\n","            else:\n","                val = [\"Down\", \"Left\", \"Up\", \"Right\"][arr[r][c]]\n","            res += \" \" + val[:5].ljust(5) + \" |\" # format\n","        res += \"\\n\"\n","    print(res)\n","\n","# Get the utility of the state reached by performing the given action from the given state\n","def getU(U, r, c, action):\n","    dr, dc = ACTIONS[action]\n","    newR, newC = r+dr, c+dc\n","    if newR < 0 or newC < 0 or newR >= NUM_ROW or newC >= NUM_COL or (newR == newC == 1): # collide with the boundary or the wall\n","        return U[r][c]\n","    else:\n","        return U[newR][newC]\n","\n","# Calculate the utility of a state given an action\n","def calculateU(U, r, c, action):\n","    u = REWARD\n","    u += 0.1 * DISCOUNT * getU(U, r, c, (action-1)%4)\n","    u += 0.8 * DISCOUNT * getU(U, r, c, action)\n","    u += 0.1 * DISCOUNT * getU(U, r, c, (action+1)%4)\n","    return u\n","\n","# Perform some simplified value iteration steps to get an approximation of the utilities\n","def policyEvaluation(policy, U):\n","    while True:\n","        nextU = [[0, 0, 0, 1], [0, 0, 0, -1], [0, 0, 0, 0], [0, 0, 0, 0]]\n","        error = 0\n","        for r in range(NUM_ROW):\n","            for c in range(NUM_COL):\n","                if (r <= 1 and c == 3) or (r == c == 1):\n","                    continue\n","                nextU[r][c] = calculateU(U, r, c, policy[r][c]) # simplified Bellman update\n","                error = max(error, abs(nextU[r][c]-U[r][c]))\n","        U = nextU\n","        if error < MAX_ERROR * (1-DISCOUNT) / DISCOUNT:\n","            break\n","    return U\n","\n","def policyIteration(policy, U):\n","    print(\"During the policy iteration:\\n\")\n","    while True:\n","        U = policyEvaluation(policy, U)\n","        unchanged = True\n","        for r in range(NUM_ROW):\n","            for c in range(NUM_COL):\n","                if (r <= 1 and c == 3) or (r == c == 1):\n","                    continue\n","                maxAction, maxU = None, -float(\"inf\")\n","                for action in range(NUM_ACTIONS):\n","                    u = calculateU(U, r, c, action)\n","                    if u > maxU:\n","                        maxAction, maxU = action, u\n","                if maxU > calculateU(U, r, c, policy[r][c]):\n","                    policy[r][c] = maxAction # the action that maximizes the utility\n","                    unchanged = False\n","        if unchanged:\n","            break\n","        printEnvironment(policy)\n","    return policy\n","\n","# Print the initial environment\n","print(\"The initial random policy is:\\n\")\n","printEnvironment(policy)\n","\n","# Policy iteration\n","policy = policyIteration(policy, U)\n","\n","# Print the optimal policy\n","print(\"The optimal policy is:\\n\")\n","printEnvironment(policy)"]},{"cell_type":"code","source":[],"metadata":{"id":"SgnEQIA-rR04"},"execution_count":null,"outputs":[]}]}